{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n",
      "<module 'posixpath' from '/Users/wayenvan/opt/anaconda3/lib/python3.8/posixpath.py'>\n",
      "Keras:  2.4.3\n",
      "TF:  2.3.1\n",
      "\n",
      "\n",
      "You are good to go\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Misc\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(sys.version)\n",
    "print(os.path)\n",
    "print(\"Keras: \",keras.__version__)\n",
    "print(\"TF: \",tf.__version__)\n",
    "print(\"\\n\\nYou are good to go\")\n",
    "\n",
    "#\n",
    "from approximator import *\n",
    "from q_learning_nn import *\n",
    "from evaluation import *\n",
    "\n",
    "#import environment\n",
    "sys.path.append(r'../virl')\n",
    "import virl\n",
    "\n",
    "#time\n",
    "import time\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training phase\n",
    "define some properities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training environment, I am using \n",
    "alpha = 0.004\n",
    "nn_config = [36,36]\n",
    "BATCH_SIZE = 80\n",
    "BUFFER_SIZE = 8000\n",
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train every insances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 999/1000, score: 51, epsilon: 0.0075"
     ]
    }
   ],
   "source": [
    "for num_instance in range(7, 10):\n",
    "  env_train = virl.Epidemic(problem_id=num_instance, stochastic=False, noisy=False) \n",
    "  d_states = env_train.observation_space.shape[0]\n",
    "  n_actions = env_train.action_space.n\n",
    "\n",
    "  # Init the tow networksis\n",
    "  nn_func_approximator_target = NNFunctionApproximatorJointKeras(alpha, d_states, n_actions, nn_config)\n",
    "\n",
    "  # Training   \n",
    "  stats = q_learning_nn(env_train, nn_func_approximator, nn_func_approximator_target, num_episodes,\n",
    "                  use_normalization = True,\n",
    "                  max_steps_per_episode=500,discount_factor=0.9, \n",
    "                  epsilon_init=0.1,epsilon_decay=0.99995,epsilon_min=0.001,\n",
    "                  use_batch_updates=True, BATCH_SIZE=BATCH_SIZE,\n",
    "                  fn_model_in=None, fn_model_out=r\"./data/approximator_training/cartpole0\"+str(num_instance)+\".h5\", BUFFER_SIZE=BUFFER_SIZE)\n",
    "  \n",
    "  #save stats\n",
    "  stats_storage = Stats_storage(stats)\n",
    "  save_variable(stats_storage, \"./data/stats_training/stats_train0\"+str(num_instance)+\".dat\")\n",
    "\n",
    "  #output log\n",
    "  t = time.localtime()\n",
    "  current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "\n",
    "  #output log\n",
    "  date = date.today()\n",
    "  log = open(\"./data/training.log\", \"a\")\n",
    "  log.write(\"problem_id = {} finished training in {} {}\\n\".format(num_instance, current_time, date))\n",
    "  log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
